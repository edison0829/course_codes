{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Ruotian Jiang ID:8389636738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multi-class Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
      "6967  1.000000  0.414643  0.601373  0.290996 -0.129241  0.129944  0.225549   \n",
      "6073  1.000000  0.124066  0.326223  0.322246  0.160067  0.175506  0.098002   \n",
      "3855  1.000000  0.208916  0.214381  0.528076  0.177962  0.027795 -0.143063   \n",
      "1067  1.000000  0.358286  0.178984  0.315646  0.058655  0.062652  0.157903   \n",
      "334   1.000000  0.611662  0.623435  0.435339 -0.149788 -0.056173  0.284499   \n",
      "3367  1.000000  0.035664 -0.020589  0.481677  0.203913  0.107837 -0.072252   \n",
      "4503  1.000000  0.249790  0.192862  0.544004  0.187089  0.061410 -0.096554   \n",
      "5971  1.000000  0.068896  0.324979  0.409920  0.239331  0.228214  0.145415   \n",
      "5877  0.993403  0.810203  1.000000  0.398418 -0.314860  0.181392 -0.074023   \n",
      "3225  1.000000  0.093211 -0.014894  0.444653  0.218826  0.083361 -0.081022   \n",
      "2577  1.000000  0.453291  0.436329  0.604977  0.015944 -0.038978 -0.041440   \n",
      "7181  1.000000 -0.442139 -0.328404  0.031452  0.056017  0.424856  0.073288   \n",
      "5912  1.000000  0.123192  0.625375  0.385779  0.170994  0.194371  0.011831   \n",
      "5182  0.701737  1.000000  0.590480  0.014940  0.207280  0.152265  0.138374   \n",
      "750   1.000000  0.025389  0.007020  0.394756  0.364267  0.297478 -0.134433   \n",
      "5432  1.000000  0.620495  0.431784  0.369822  0.118892  0.197765 -0.023286   \n",
      "3127  1.000000  0.205068  0.102238  0.448495  0.183089  0.034423 -0.134965   \n",
      "1077  1.000000  0.323936  0.161757  0.362646  0.212734  0.193576  0.206381   \n",
      "495   1.000000  0.576088  0.724628  0.611427 -0.202665 -0.158261  0.498547   \n",
      "3151  1.000000  0.115495 -0.041875  0.393712  0.263379  0.089452 -0.125535   \n",
      "6559  1.000000  0.454841  0.392072  0.199927  0.072418  0.163450  0.018475   \n",
      "1118  1.000000  0.408650  0.299011  0.427176  0.116564  0.111989  0.066113   \n",
      "6065  1.000000  0.077728  0.319076  0.382461  0.271047  0.187398  0.083011   \n",
      "507   1.000000  0.478178  0.687712  0.600840 -0.222338 -0.149847  0.441022   \n",
      "4863  1.000000 -0.163059  0.243900  0.919348  0.312451 -0.270574 -0.258721   \n",
      "4182  1.000000  0.322769  0.261293  0.533220  0.155454 -0.017592 -0.115017   \n",
      "2491  1.000000  0.303454  0.292814  0.594593  0.227495  0.012051 -0.128156   \n",
      "5972  1.000000 -0.035181  0.529854  0.379470  0.188825  0.267324  0.108006   \n",
      "4543  1.000000  0.150828  0.281462  0.631126  0.164430 -0.034157 -0.149872   \n",
      "3792  1.000000  0.573732  0.389827  0.550378  0.188997  0.096848 -0.026875   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2570  1.000000  0.318266  0.331090  0.582045  0.168515  0.004192 -0.105598   \n",
      "85    1.000000  0.098821 -0.027873  0.366567  0.282226  0.202531  0.092912   \n",
      "6423  1.000000  0.286175  0.322518  0.271151  0.149404  0.235386  0.141332   \n",
      "240   1.000000  0.263413 -0.015631  0.345247  0.319541  0.281105 -0.057362   \n",
      "3137  1.000000  0.204213  0.162944  0.398550  0.237494  0.011874 -0.229038   \n",
      "5559  1.000000  0.264562  0.338498  0.268476  0.126068  0.186439  0.091486   \n",
      "1612  1.000000  0.149851  0.112563  0.549952  0.194901 -0.002523 -0.145913   \n",
      "4346  1.000000  0.168887  0.192406  0.654584  0.212841 -0.024355 -0.156631   \n",
      "1547  1.000000  0.219926  0.084827  0.556966  0.221878  0.016882 -0.208492   \n",
      "4034  1.000000  0.427119  0.220125  0.562979  0.244256  0.076368 -0.071603   \n",
      "6386  1.000000  0.577047  0.599424  0.286141 -0.068299  0.209364  0.126564   \n",
      "2717  1.000000  0.379967  0.358531  0.634291  0.171856  0.018631 -0.094744   \n",
      "5324  0.522401  0.816611  1.000000  0.445617 -0.097785  0.363190  0.130721   \n",
      "665   1.000000  0.550072  0.680368  0.526546 -0.227932 -0.048582  0.365809   \n",
      "6707  1.000000  0.140729  0.553648  0.420359 -0.164913  0.307186  0.349276   \n",
      "6149  1.000000  0.001255  0.498003  0.335919  0.184800  0.311481  0.069430   \n",
      "7171  1.000000  0.153789  0.522557  0.267617 -0.043499  0.034436  0.081305   \n",
      "5270  1.000000  0.806916  0.757806  0.228922 -0.024011  0.338168  0.022767   \n",
      "5346  0.792931  0.517929  1.000000  0.428241 -0.224669  0.370110  0.140165   \n",
      "5141  1.000000  0.563680  0.603666  0.375964 -0.067332  0.060819 -0.008401   \n",
      "4085  1.000000  0.394040  0.239677  0.506318  0.144439  0.020232 -0.102930   \n",
      "3529  1.000000  0.674783  0.314017  0.502765  0.229530  0.097645 -0.065464   \n",
      "6655  1.000000  0.409119  0.781377  0.217255 -0.114927  0.347842  0.137104   \n",
      "2649  1.000000  0.340502  0.376815  0.548787  0.097215 -0.024784 -0.039330   \n",
      "3262  1.000000 -0.087672  0.157097  0.428506  0.122577  0.124174 -0.062767   \n",
      "364   1.000000  0.675086  0.760598  0.595568 -0.120323 -0.082668  0.425594   \n",
      "6738  1.000000  0.234418  0.842582  0.254435 -0.267554  0.398035  0.152505   \n",
      "975   1.000000  0.262282 -0.138702  0.152866  0.376564  0.170391 -0.125736   \n",
      "4078  1.000000  0.355538  0.265763  0.592074  0.266021  0.058226 -0.114066   \n",
      "4890  1.000000  0.186280  0.062700  0.395142  0.272496  0.196474  0.039701   \n",
      "\n",
      "      MFCCs_ 8  MFCCs_ 9  MFCCs_10    ...     MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
      "6967 -0.068793 -0.062265  0.144588    ...     0.000880  0.076793 -0.014580   \n",
      "6073 -0.136502 -0.050603  0.099387    ...     0.096462  0.015151  0.014499   \n",
      "3855 -0.007352  0.264521  0.066120    ...     0.314139  0.074735 -0.124466   \n",
      "1067 -0.033227 -0.248051 -0.136577    ...    -0.112278  0.091645  0.054971   \n",
      "334  -0.027369 -0.253056  0.189023    ...     0.093432  0.110127 -0.070960   \n",
      "3367 -0.013965  0.178226  0.059062    ...     0.271537  0.146953 -0.062211   \n",
      "4503  0.007734  0.241336  0.008358    ...     0.192469 -0.123839 -0.186294   \n",
      "5971 -0.163170 -0.058468  0.106222    ...     0.087704  0.026224  0.031971   \n",
      "5877 -0.304611  0.053490  0.154957    ...     0.015765  0.149672  0.028298   \n",
      "3225  0.023475  0.219545  0.079246    ...     0.225342  0.062111 -0.123209   \n",
      "2577  0.110560  0.283017 -0.030467    ...     0.252102 -0.046311 -0.095329   \n",
      "7181 -0.140148  0.043070  0.087675    ...     0.024943  0.068279  0.015953   \n",
      "5912 -0.036806  0.044600  0.071978    ...     0.159256 -0.036891  0.025869   \n",
      "5182  0.016109  0.106136 -0.058897    ...     0.016874  0.061348  0.035824   \n",
      "750  -0.292976  0.020176  0.209432    ...    -0.201505 -0.018177  0.126085   \n",
      "5432  0.068672  0.189003 -0.047349    ...    -0.070490 -0.018428  0.003701   \n",
      "3127 -0.045123  0.215725  0.099403    ...     0.238919  0.116479 -0.045278   \n",
      "1077 -0.022602 -0.221416 -0.021896    ...    -0.112186  0.108336  0.052571   \n",
      "495   0.037025 -0.357460  0.145946    ...     0.044030  0.187411 -0.089496   \n",
      "3151 -0.056173  0.222615  0.133734    ...     0.271101  0.104371 -0.135662   \n",
      "6559 -0.084305  0.089732  0.076231    ...     0.020169 -0.024294 -0.011039   \n",
      "1118 -0.007364 -0.209218 -0.038743    ...    -0.134819  0.015216 -0.018143   \n",
      "6065 -0.167949 -0.056731  0.110858    ...     0.065645  0.001686  0.026620   \n",
      "507   0.071143 -0.346294  0.142127    ...     0.057584  0.136974 -0.046876   \n",
      "4863  0.066770  0.393374  0.159481    ...     0.234785  0.082161 -0.024100   \n",
      "4182  0.118616  0.317986  0.071401    ...     0.191403  0.126408 -0.041642   \n",
      "2491  0.055445  0.352383  0.049462    ...     0.220415 -0.002808 -0.098841   \n",
      "5972 -0.116015 -0.006054  0.148113    ...     0.218804  0.037956 -0.021557   \n",
      "4543  0.037861  0.190081 -0.075216    ...     0.177458 -0.143994 -0.168517   \n",
      "3792 -0.040371  0.245342  0.079729    ...     0.298435 -0.005726 -0.061613   \n",
      "...        ...       ...       ...    ...          ...       ...       ...   \n",
      "2570  0.088642  0.265000 -0.026160    ...     0.230161 -0.026979 -0.117264   \n",
      "85   -0.184680 -0.229183  0.236332    ...    -0.080103 -0.131398 -0.114746   \n",
      "6423 -0.131558 -0.071416  0.105002    ...     0.113870  0.017836 -0.032157   \n",
      "240  -0.248135 -0.065514  0.356200    ...    -0.029198 -0.117828 -0.141050   \n",
      "3137  0.020603  0.239535  0.101843    ...     0.202797  0.095640 -0.142041   \n",
      "5559 -0.096505 -0.006358  0.094866    ...     0.062541  0.016702  0.008067   \n",
      "1612  0.043579  0.312533  0.089307    ...     0.226256  0.081210 -0.109910   \n",
      "4346  0.120363  0.280700 -0.036166    ...     0.219590 -0.094963 -0.138368   \n",
      "1547  0.030874  0.296598  0.048372    ...     0.227369  0.066696 -0.114916   \n",
      "4034  0.065820  0.259136  0.067629    ...     0.140408  0.001615 -0.126533   \n",
      "6386 -0.082796  0.075530  0.142788    ...    -0.036369  0.029189  0.022383   \n",
      "2717  0.038405  0.239545 -0.061527    ...     0.142640 -0.034309 -0.087408   \n",
      "5324  0.191741  0.203372 -0.265941    ...    -0.241549  0.171010 -0.159028   \n",
      "665   0.003393 -0.299613  0.152431    ...     0.004444  0.068636 -0.098707   \n",
      "6707 -0.179732  0.020416  0.134413    ...    -0.007730 -0.078749 -0.002650   \n",
      "6149 -0.127911 -0.009922  0.062139    ...     0.105540  0.008704  0.019911   \n",
      "7171  0.113272 -0.034906 -0.055563    ...    -0.005648 -0.028727  0.031281   \n",
      "5270  0.101965  0.220019 -0.128826    ...    -0.021655  0.105244 -0.005484   \n",
      "5346 -0.029107  0.167507 -0.138225    ...    -0.128615 -0.124852  0.053812   \n",
      "5141  0.106996  0.156144 -0.276008    ...    -0.068871 -0.019738  0.003745   \n",
      "4085  0.052589  0.307883  0.063319    ...     0.262070  0.088261 -0.104553   \n",
      "3529  0.044617  0.267579  0.093564    ...     0.239784  0.033304 -0.071571   \n",
      "6655 -0.235817  0.132429  0.252549    ...     0.080634 -0.080597 -0.058551   \n",
      "2649  0.089816  0.282974 -0.002933    ...     0.128919 -0.061982 -0.110996   \n",
      "3262  0.109531  0.219579  0.026816    ...     0.181860  0.058007 -0.109328   \n",
      "364   0.048207 -0.277741  0.120096    ...     0.053920  0.057901 -0.053057   \n",
      "6738 -0.255480  0.090854  0.174819    ...     0.096062 -0.092657 -0.021028   \n",
      "975   0.021182  0.203708  0.134288    ...    -0.089493 -0.047954  0.029709   \n",
      "4078  0.059208  0.320396  0.048102    ...     0.189554  0.087363 -0.126651   \n",
      "4890 -0.231683 -0.068564  0.329522    ...    -0.111826  0.016808  0.111894   \n",
      "\n",
      "      MFCCs_20  MFCCs_21  MFCCs_22           Family          Genus  \\\n",
      "6967 -0.050034  0.039031  0.038611          Hylidae  Osteocephalus   \n",
      "6073 -0.013808 -0.074134 -0.027614          Hylidae      Hypsiboas   \n",
      "3855 -0.134086 -0.033589  0.174705  Leptodactylidae      Adenomera   \n",
      "1067 -0.008307 -0.034183 -0.041301    Dendrobatidae       Ameerega   \n",
      "334   0.012922  0.084341 -0.000695  Leptodactylidae      Adenomera   \n",
      "3367 -0.229611 -0.078972  0.241784  Leptodactylidae      Adenomera   \n",
      "4503 -0.065505  0.159171  0.174401  Leptodactylidae      Adenomera   \n",
      "5971  0.019567 -0.046138 -0.005580          Hylidae      Hypsiboas   \n",
      "5877 -0.041673 -0.072595  0.062839          Hylidae      Hypsiboas   \n",
      "3225 -0.188078 -0.022648  0.183467  Leptodactylidae      Adenomera   \n",
      "2577 -0.014885  0.086728  0.128639  Leptodactylidae      Adenomera   \n",
      "7181  0.058530 -0.009746 -0.080940          Hylidae         Scinax   \n",
      "5912  0.067956 -0.000366  0.005707          Hylidae      Hypsiboas   \n",
      "5182 -0.019145  0.053943 -0.026383          Hylidae      Hypsiboas   \n",
      "750   0.117203 -0.019891 -0.092242    Dendrobatidae       Ameerega   \n",
      "5432  0.009567  0.059589 -0.050661          Hylidae      Hypsiboas   \n",
      "3127 -0.121002 -0.035277  0.169055  Leptodactylidae      Adenomera   \n",
      "1077 -0.075150 -0.039305 -0.016147    Dendrobatidae       Ameerega   \n",
      "495  -0.084500  0.085116  0.078416  Leptodactylidae      Adenomera   \n",
      "3151 -0.238869 -0.029682  0.244420  Leptodactylidae      Adenomera   \n",
      "6559 -0.014447  0.002517  0.048504          Hylidae      Hypsiboas   \n",
      "1118 -0.085998  0.009651  0.068194    Dendrobatidae       Ameerega   \n",
      "6065  0.013197 -0.052861 -0.021602          Hylidae      Hypsiboas   \n",
      "507  -0.099424  0.021916  0.021012  Leptodactylidae      Adenomera   \n",
      "4863 -0.078968 -0.039117  0.087610          Hylidae  Dendropsophus   \n",
      "4182 -0.166793  0.041264  0.262622  Leptodactylidae      Adenomera   \n",
      "2491 -0.133541  0.034412  0.201603  Leptodactylidae      Adenomera   \n",
      "5972  0.018420 -0.000653  0.012299          Hylidae      Hypsiboas   \n",
      "4543 -0.035200  0.181745  0.167878  Leptodactylidae      Adenomera   \n",
      "3792 -0.076759 -0.015327  0.144073  Leptodactylidae      Adenomera   \n",
      "...        ...       ...       ...              ...            ...   \n",
      "2570 -0.075657  0.101667  0.146862  Leptodactylidae      Adenomera   \n",
      "85   -0.038608  0.141710  0.110473  Leptodactylidae      Adenomera   \n",
      "6423 -0.007912 -0.028665 -0.033894          Hylidae      Hypsiboas   \n",
      "240   0.078228  0.258251  0.064930  Leptodactylidae      Adenomera   \n",
      "3137 -0.168370 -0.003067  0.205727  Leptodactylidae      Adenomera   \n",
      "5559 -0.015892 -0.026908  0.017870          Hylidae      Hypsiboas   \n",
      "1612 -0.170192  0.041451  0.212499  Leptodactylidae      Adenomera   \n",
      "4346 -0.050420  0.175365  0.152856  Leptodactylidae      Adenomera   \n",
      "1547 -0.170998  0.067898  0.252491  Leptodactylidae      Adenomera   \n",
      "4034 -0.169823  0.065475  0.178421  Leptodactylidae      Adenomera   \n",
      "6386 -0.042960 -0.017411  0.049210          Hylidae      Hypsiboas   \n",
      "2717 -0.081687  0.082987  0.143594  Leptodactylidae      Adenomera   \n",
      "5324 -0.196553 -0.175224 -0.062986          Hylidae      Hypsiboas   \n",
      "665  -0.058955  0.074105  0.013602  Leptodactylidae      Adenomera   \n",
      "6707  0.126504  0.074541 -0.105043  Leptodactylidae  Leptodactylus   \n",
      "6149 -0.012988 -0.036435  0.057245          Hylidae      Hypsiboas   \n",
      "7171  0.033687  0.005242  0.014982          Hylidae         Scinax   \n",
      "5270  0.099036  0.140237 -0.076224          Hylidae      Hypsiboas   \n",
      "5346  0.097624 -0.034079 -0.077820          Hylidae      Hypsiboas   \n",
      "5141  0.025786  0.027535 -0.174426          Hylidae      Hypsiboas   \n",
      "4085 -0.194088  0.042593  0.231235  Leptodactylidae      Adenomera   \n",
      "3529 -0.172259  0.030331  0.208549  Leptodactylidae      Adenomera   \n",
      "6655  0.089933  0.004744 -0.058820  Leptodactylidae  Leptodactylus   \n",
      "2649 -0.054829  0.051207  0.110998  Leptodactylidae      Adenomera   \n",
      "3262 -0.124084  0.071864  0.255170  Leptodactylidae      Adenomera   \n",
      "364   0.004814  0.082563  0.009058  Leptodactylidae      Adenomera   \n",
      "6738  0.131876  0.018577 -0.142408  Leptodactylidae  Leptodactylus   \n",
      "975  -0.059110 -0.089941  0.008346    Dendrobatidae       Ameerega   \n",
      "4078 -0.199444  0.028315  0.213887  Leptodactylidae      Adenomera   \n",
      "4890  0.173187  0.036212 -0.173652          Hylidae  Dendropsophus   \n",
      "\n",
      "                     Species  RecordID  \n",
      "6967   OsteocephalusOophagus        50  \n",
      "6073       HypsiboasCordobae        41  \n",
      "3855  AdenomeraHylaedactylus        22  \n",
      "1067      Ameeregatrivittata        13  \n",
      "334           AdenomeraAndre         8  \n",
      "3367  AdenomeraHylaedactylus        21  \n",
      "4503  AdenomeraHylaedactylus        24  \n",
      "5971       HypsiboasCordobae        41  \n",
      "5877       HypsiboasCordobae        41  \n",
      "3225  AdenomeraHylaedactylus        21  \n",
      "2577  AdenomeraHylaedactylus        19  \n",
      "7181             ScinaxRuber        60  \n",
      "5912       HypsiboasCordobae        41  \n",
      "5182    HypsiboasCinerascens        36  \n",
      "750       Ameeregatrivittata        10  \n",
      "5432    HypsiboasCinerascens        38  \n",
      "3127  AdenomeraHylaedactylus        21  \n",
      "1077      Ameeregatrivittata        13  \n",
      "495           AdenomeraAndre         8  \n",
      "3151  AdenomeraHylaedactylus        21  \n",
      "6559       HypsiboasCordobae        43  \n",
      "1118      Ameeregatrivittata        13  \n",
      "6065       HypsiboasCordobae        41  \n",
      "507           AdenomeraAndre         8  \n",
      "4863              HylaMinuta        30  \n",
      "4182  AdenomeraHylaedactylus        23  \n",
      "2491  AdenomeraHylaedactylus        19  \n",
      "5972       HypsiboasCordobae        41  \n",
      "4543  AdenomeraHylaedactylus        24  \n",
      "3792  AdenomeraHylaedactylus        22  \n",
      "...                      ...       ...  \n",
      "2570  AdenomeraHylaedactylus        19  \n",
      "85            AdenomeraAndre         2  \n",
      "6423       HypsiboasCordobae        42  \n",
      "240           AdenomeraAndre         6  \n",
      "3137  AdenomeraHylaedactylus        21  \n",
      "5559       HypsiboasCordobae        40  \n",
      "1612  AdenomeraHylaedactylus        15  \n",
      "4346  AdenomeraHylaedactylus        24  \n",
      "1547  AdenomeraHylaedactylus        15  \n",
      "4034  AdenomeraHylaedactylus        23  \n",
      "6386       HypsiboasCordobae        42  \n",
      "2717  AdenomeraHylaedactylus        19  \n",
      "5324    HypsiboasCinerascens        37  \n",
      "665           AdenomeraAndre         8  \n",
      "6707     LeptodactylusFuscus        47  \n",
      "6149       HypsiboasCordobae        41  \n",
      "7171             ScinaxRuber        59  \n",
      "5270    HypsiboasCinerascens        37  \n",
      "5346    HypsiboasCinerascens        37  \n",
      "5141    HypsiboasCinerascens        36  \n",
      "4085  AdenomeraHylaedactylus        23  \n",
      "3529  AdenomeraHylaedactylus        22  \n",
      "6655     LeptodactylusFuscus        46  \n",
      "2649  AdenomeraHylaedactylus        19  \n",
      "3262  AdenomeraHylaedactylus        21  \n",
      "364           AdenomeraAndre         8  \n",
      "6738     LeptodactylusFuscus        47  \n",
      "975       Ameeregatrivittata        11  \n",
      "4078  AdenomeraHylaedactylus        23  \n",
      "4890              HylaMinuta        32  \n",
      "\n",
      "[2159 rows x 26 columns]\n",
      "[['Hylidae' 'Osteocephalus' 'OsteocephalusOophagus']\n",
      " ['Hylidae' 'Hypsiboas' 'HypsiboasCordobae']\n",
      " ['Leptodactylidae' 'Adenomera' 'AdenomeraHylaedactylus']\n",
      " ...\n",
      " ['Dendrobatidae' 'Ameerega' 'Ameeregatrivittata']\n",
      " ['Leptodactylidae' 'Adenomera' 'AdenomeraHylaedactylus']\n",
      " ['Hylidae' 'Dendropsophus' 'HylaMinuta']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "df = pd.read_csv('Frogs_MFCCs.csv',delimiter=',')  \n",
    "train, test = train_test_split(df, train_size=0.7)\n",
    "print test\n",
    "print test.iloc[:,22:25].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b (i)\n",
    "Accuracy classification score:\n",
    "\n",
    "Exact match: is the most strict metric, indicating the percentage of samples that have all their labels classified correctly.\n",
    "\n",
    "In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
    "\n",
    "\n",
    "Compute the average Hamming loss:\n",
    "\n",
    "Hamming loss: the fraction of the wrong labels to the total number of labels\n",
    "\n",
    "The Hamming loss is the fraction of labels that are incorrectly predicted.\n",
    "\n",
    "but in this question, multiclass-multioutput is not supported with sklearn\n",
    "\n",
    "\n",
    "hamming score:\n",
    "\n",
    "Another typical way to compute the accuracy is defined in (1) and (2), and less ambiguously referred to as the Hamming score (4) (since it is closely related to the Hamming loss), or label-based accuracy). It is computed as follows:\n",
    "\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    https://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "# hamming_loss(y_true, y_pred)\n",
    "# accuracy_score(y_true, y_pred)\n",
    "\n",
    "# used in evaluating multilabel classification \n",
    "def hamming_score(y_true, y_pred):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( y_true[i] )\n",
    "        set_pred = set( y_pred[i] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "\n",
    "        tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "\n",
    "def exact_match(y_true, y_pred):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (y_true[i][1] == y_pred[i][1]) and (y_true[i][0] == y_pred[i][0]) and (y_true[i][2] == y_pred[i][2]):    \n",
    "            acc_list.append(1)\n",
    "        else:\n",
    "            acc_list.append(0)\n",
    "    return np.mean(acc_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i decided to use the method like this example:\n",
    "import numpy as np\n",
    "y_true = np.array([[1, 1], [2, 3]])\n",
    "y_pred = np.array([[0, 1], [1, 2]])\n",
    "hamming_loss_value = np.sum(np.not_equal(y_true, y_pred))/float(y_true.size)\n",
    "accuracy_score_value = 1 - hamming_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b (ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Families label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9921259842519685\n",
      "single hamming loss\n",
      "0.007874015748031496\n",
      "single match accuracy\n",
      "0.9921259842519685\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,22:23]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,22:23]\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X, train_y)\n",
    "\n",
    "y_pred_families = grid.predict(test_X)\n",
    "\n",
    "y_pred = grid.predict(test_X)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genus label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9879573876794813\n",
      "single hamming loss\n",
      "0.012042612320518759\n",
      "single match accuracy\n",
      "0.9879573876794813\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,23:24]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,23:24]\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X, train_y)\n",
    "\n",
    "y_pred_genus = grid.predict(test_X)\n",
    "\n",
    "y_pred = grid.predict(test_X)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9874942102825383\n",
      "single hamming loss\n",
      "0.012505789717461788\n",
      "single match accuracy\n",
      "0.9874942102825383\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,24:25]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,24:25]\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X, train_y)\n",
    "\n",
    "y_pred_species = grid.predict(test_X)\n",
    "\n",
    "y_pred = grid.predict(test_X)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss\n",
      "0.010807472595337347\n",
      "hamming score\n",
      "0.9876794812413152\n",
      "exact match score\n",
      "0.984251968503937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_true = test.iloc[:,22:25].values\n",
    "y_pred_families = y_pred_families.reshape(2159,1)\n",
    "y_pred_genus = y_pred_genus.reshape(2159,1)\n",
    "y_pred_species =y_pred_species.reshape(2159,1)\n",
    "y_pred = np.concatenate((y_pred_families,y_pred_genus,y_pred_species), axis=1)\n",
    "hamming_loss_value = np.sum(np.not_equal(y_true, y_pred))/float(y_true.size)\n",
    "hamming_score_value = hamming_score(y_true, y_pred)\n",
    "accuracy_score_value = exact_match(y_true, y_pred)\n",
    "\n",
    "print 'hamming loss'\n",
    "print hamming_loss_value\n",
    "print 'hamming score'\n",
    "print hamming_score_value\n",
    "print 'exact match score'\n",
    "print accuracy_score_value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalized attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df):\n",
    "    df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "    return df_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Families label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.983788791106994\n",
      "single hamming loss\n",
      "0.01621120889300602\n",
      "single match accuracy\n",
      "0.983788791106994\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,22:23]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,22:23]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_families = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genus label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9865678554886521\n",
      "single hamming loss\n",
      "0.013432144511347846\n",
      "single match accuracy\n",
      "0.9865678554886521\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,23:24]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,23:24]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_genus = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9814729041222788\n",
      "single hamming loss\n",
      "0.018527095877721167\n",
      "single match accuracy\n",
      "0.9814729041222788\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,24:25]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,24:25]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "# the weight of the SVM penalty\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "# the width of the Gaussian Kernel\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# the process of determining\n",
    "clf = svm.SVC(decision_function_shape='ovr',kernel='rbf')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_species = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss\n",
      "0.016056816427358345\n",
      "hamming score\n",
      "0.9799907364520613\n",
      "exact match score\n",
      "0.9698934691987031\n"
     ]
    }
   ],
   "source": [
    "y_true = test.iloc[:,22:25].values\n",
    "y_pred_families = y_pred_families.reshape(2159,1)\n",
    "y_pred_genus = y_pred_genus.reshape(2159,1)\n",
    "y_pred_species =y_pred_species.reshape(2159,1)\n",
    "y_pred = np.concatenate((y_pred_families,y_pred_genus,y_pred_species), axis=1)\n",
    "hamming_loss_value = np.sum(np.not_equal(y_true, y_pred))/float(y_true.size)\n",
    "hamming_score_value = hamming_score(y_true, y_pred)\n",
    "accuracy_score_value = exact_match(y_true, y_pred)\n",
    "\n",
    "print 'hamming loss'\n",
    "print hamming_loss_value\n",
    "print 'hamming score'\n",
    "print hamming_score_value\n",
    "print 'exact match score'\n",
    "print accuracy_score_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b(iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Families label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9272811486799444\n",
      "single hamming loss\n",
      "0.07271885132005558\n",
      "single match accuracy\n",
      "0.9272811486799444\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,22:23]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,22:23]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_families = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genus label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9397869383974062\n",
      "single hamming loss\n",
      "0.06021306160259379\n",
      "single match accuracy\n",
      "0.9397869383974062\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,23:24]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,23:24]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_genus = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9490504863362668\n",
      "single hamming loss\n",
      "0.05094951366373321\n",
      "single match accuracy\n",
      "0.9490504863362668\n"
     ]
    }
   ],
   "source": [
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,24:25]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,24:25]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_species = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss\n",
      "0.06129380886212753\n",
      "hamming score\n",
      "0.9289485873089393\n",
      "exact match score\n",
      "0.905048633626679\n"
     ]
    }
   ],
   "source": [
    "y_true = test.iloc[:,22:25].values\n",
    "y_pred_families = y_pred_families.reshape(2159,1)\n",
    "y_pred_genus = y_pred_genus.reshape(2159,1)\n",
    "y_pred_species =y_pred_species.reshape(2159,1)\n",
    "y_pred = np.concatenate((y_pred_families,y_pred_genus,y_pred_species), axis=1)\n",
    "hamming_loss_value = np.sum(np.not_equal(y_true, y_pred))/float(y_true.size)\n",
    "hamming_score_value = hamming_score(y_true, y_pred)\n",
    "accuracy_score_value = exact_match(y_true, y_pred)\n",
    "\n",
    "print 'hamming loss'\n",
    "print hamming_loss_value\n",
    "print 'hamming score'\n",
    "print hamming_score_value\n",
    "print 'exact match score'\n",
    "print accuracy_score_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b (iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Families label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.8957850856878184\n",
      "single hamming loss\n",
      "0.10421491431218156\n",
      "single match accuracy\n",
      "0.8957850856878184\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,22:23]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,22:23]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "train_X_norm,train_y = sm.fit_sample(train_X_norm,train_y)\n",
    "\n",
    "\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_families = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genus label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.8689207966651228\n",
      "single hamming loss\n",
      "0.13107920333487727\n",
      "single match accuracy\n",
      "0.8689207966651228\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,23:24]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,23:24]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "train_X_norm,train_y = sm.fit_sample(train_X_norm,train_y)\n",
    "\n",
    "\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_genus = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifer score\n",
      "0.9407132931912923\n",
      "single hamming loss\n",
      "0.059286706808707734\n",
      "single match accuracy\n",
      "0.9407132931912923\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,24:25]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,24:25]\n",
    "\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "train_X_norm,train_y = sm.fit_sample(train_X_norm,train_y)\n",
    "\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "param_grid = dict( C=C_range)\n",
    "# determining the weight of the SVM penalty\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "grid.fit(train_X_norm, train_y)\n",
    "y_pred_species = grid.predict(test_X_norm)\n",
    "\n",
    "y_pred = grid.predict(test_X_norm)\n",
    "print 'single classifer score'\n",
    "print grid.score(test_X_norm,test_y)\n",
    "print 'single hamming loss'\n",
    "print hamming_loss(test_y, y_pred)\n",
    "print 'single match accuracy'\n",
    "print accuracy_score(test_y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss\n",
      "0.09819360815192218\n",
      "hamming score\n",
      "0.8792959703566466\n",
      "exact match score\n",
      "0.824918943955535\n"
     ]
    }
   ],
   "source": [
    "y_true = test.iloc[:,22:25].values\n",
    "y_pred_families = y_pred_families.reshape(2159,1)\n",
    "y_pred_genus = y_pred_genus.reshape(2159,1)\n",
    "y_pred_species =y_pred_species.reshape(2159,1)\n",
    "y_pred = np.concatenate((y_pred_families,y_pred_genus,y_pred_species), axis=1)\n",
    "hamming_loss_value = np.sum(np.not_equal(y_true, y_pred))/float(y_true.size)\n",
    "hamming_score_value = hamming_score(y_true, y_pred)\n",
    "accuracy_score_value = exact_match(y_true, y_pred)\n",
    "\n",
    "print 'hamming loss'\n",
    "print hamming_loss_value\n",
    "print 'hamming score'\n",
    "print hamming_score_value\n",
    "print 'exact match score'\n",
    "print accuracy_score_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obviously, in this question, SMOTE did not improve the result, the accuracy is lower than L1-penalized SVMs without SMOTE. The result is not so good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b (v) Extra Practice: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Families label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "\n",
    "train_X=train.iloc[:,0:22]\n",
    "train_y=train.iloc[:,22:23]\n",
    "test_X=test.iloc[:,0:22]\n",
    "test_y=test.iloc[:,22:23]\n",
    "train_y.replace({ 'Leptodactylidae' : 2, 'Dendrobatidae' : 1, 'Hylidae' : 3, 'Bufonidae' :4})\n",
    "test_y.replace({ 'Leptodactylidae' : 2, 'Dendrobatidae' : 1, 'Hylidae' : 3, 'Bufonidae' :4})\n",
    "train_X_norm = norm(train_X)\n",
    "test_X_norm = norm(test_X)\n",
    "\n",
    "train_X_norm,train_y = sm.fit_sample(train_X_norm,train_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = svm.LinearSVC(penalty='l1',dual=False,multi_class='ovr')\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "clf.fit(train_X_norm, train_y)\n",
    "y_pred = clf.predict(test_X_norm)\n",
    "\n",
    "ovr_jaccard_score = jaccard_similarity_score(test_y, y_pred)\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(clf,cv=cv, order='random', random_state=i)\n",
    "          for i in range(10)]\n",
    "for chain in chains:\n",
    "    chain.fit(train_X_norm, train_y)\n",
    "#  use classifier chain here\n",
    "\n",
    "Y_pred_chains = np.array([chain.predict(test_X_norm) for chain in\n",
    "                          chains])\n",
    "chain_jaccard_scores = [jaccard_similarity_score(test_y, y_pred >= .5)\n",
    "                        for Y_pred_chain in Y_pred_chains]\n",
    "\n",
    "Y_pred_ensemble = Y_pred_chains.mean(axis=0)\n",
    "ensemble_jaccard_score = jaccard_similarity_score(test_y,\n",
    "                                                  Y_pred_ensemble >= .5)\n",
    "\n",
    "model_scores = [ovr_jaccard_score] + chain_jaccard_scores\n",
    "model_scores.append(ensemble_jaccard_score)\n",
    "\n",
    "model_names = ('Independent',\n",
    "               'Chain 1',\n",
    "               'Chain 2',\n",
    "               'Chain 3',\n",
    "               'Chain 4',\n",
    "               'Chain 5',\n",
    "               'Chain 6',\n",
    "               'Chain 7',\n",
    "               'Chain 8',\n",
    "               'Chain 9',\n",
    "               'Chain 10',\n",
    "               'Ensemble')\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.grid(True)\n",
    "ax.set_title('Classifier Chain Ensemble Performance Comparison')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(model_names, rotation='vertical')\n",
    "ax.set_ylabel('Jaccard Similarity Score')\n",
    "ax.set_ylim([min(model_scores) * .9, max(model_scores) * 1.1])\n",
    "colors = ['r'] + ['b'] * len(chain_jaccard_scores) + ['g']\n",
    "ax.bar(x_pos, model_scores, alpha=0.5, color=colors)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leptodactylidae' 'Leptodactylidae' 'Hylidae' ... 'Hylidae' 'Hylidae'\n",
      " 'Hylidae']\n"
     ]
    }
   ],
   "source": [
    "print train_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
